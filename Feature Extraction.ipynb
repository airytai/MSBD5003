{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instruction: 从头运行到loop work cell，之后修改日期，反复运行从loop work cell至最终的cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "if(not sc and not spark):\n",
    "    sc = SparkContext('local')\n",
    "    spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fileinput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_iid_path = \"./data/uid_iid\"\n",
    "train_set_path = \"./data/tianchi_fresh_comp_train_user.csv\"\n",
    "feature_path = \"./data/feature/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "data = sc.textFile(train_set_path, 1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "############################         数据预处理           ############################\n",
    "####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23291028"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'user_id,item_id,behavior_type,user_geohash,item_category,time',\n",
       " u'65361888,98907464,1,,9559,2014-12-13 04',\n",
       " u'65361888,98907464,1,,9559,2014-12-13 04',\n",
       " u'65361888,9679068,1,,4116,2014-12-04 03',\n",
       " u'65361888,96612624,1,,2993,2014-12-10 05',\n",
       " u'65361888,96612624,1,,2993,2014-12-10 05',\n",
       " u'65361888,96612624,1,,2993,2014-12-10 05',\n",
       " u'65361888,96584710,2,,11824,2014-12-14 07',\n",
       " u'65361888,96584710,1,,11824,2014-12-14 07',\n",
       " u'65361888,92945029,1,,434,2014-12-08 14']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data.top(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "dataheader = data.filter(lambda l: 'user_id' in l)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'user_id,item_id,behavior_type,user_geohash,item_category,time']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "dataheader.collect()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "datanoheader = data.subtract(dataheader)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23291027"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datanoheader.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def extract(line):\n",
    "    import time\n",
    "    try:\n",
    "        part = line.strip().split(\",\")\n",
    "        uid, iid, beh, ict, time = part[0], part[1], part[2], part[4], \"-\".join(part[5].split(\" \")[0].split(\"-\")[1:])+\"-\"+part[5].split(\" \")[1]\n",
    "        return ((uid, iid, ict), time+\",\"+beh)\n",
    "    except:\n",
    "        return ((\"\"), \"\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "counts = datanoheader.map(lambda x : extract(x)) \\\n",
    "                .filter(lambda x : x[0]!=\"\") \\\n",
    "                .groupByKey() \\\n",
    "                .map(lambda x : (\" \".join(x[0])+\"\\t\"+\" \".join([str(item[\"time\"])+\",\"+item[\"beh\"] for item in sorted([{\"time\":content.split(\",\")[0],\"beh\":content.split(\",\")[1]} for content in x[1]],key=lambda x:x[\"time\"])])))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "output = counts.saveAsTextFile(uid_iid_path)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "############################           商品特征           ############################\n",
    "####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract1_item(line):\n",
    "    import time\n",
    "    (uid, iid, ict) = line.strip().split(\"\\t\")[0].split(\" \")\n",
    "    if subset.has_key(iid):\n",
    "        items = filter(lambda x:x[0]>0, [(int(time.mktime(time.strptime('2014-'+etime,'%Y-%m-%d-%H'))-time.mktime(time.strptime('2014-'+i.split(\",\")[0],'%Y-%m-%d-%H')))/(24*3600)+1, int(i.split(\",\")[1])) for i in line.strip().split(\"\\t\")[1].split(\" \")])\n",
    "        return (iid,items)\n",
    "    else:\n",
    "        return (\"\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract2_item(items_list):\n",
    "    items, items_buy, items_buy_3, f, inf = [], [], [], [0]*37, 100\n",
    "    f[30] = len(items_list) # 交互人数\n",
    "    for i in items_list:\n",
    "        if len(filter(lambda x:x[1]==4,i))>0:\n",
    "            items_buy.append(i)\n",
    "        if len(filter(lambda x:x[1]==4 and x[0]<=3,i))>0:\n",
    "            items_buy_3.append(i)\n",
    "        items.extend(i)\n",
    "    f[31] = len(items_buy) # 购买人数\n",
    "    f[32] = len(items_buy_3) # 三天内购买人数\n",
    "    f[33] = len(filter(lambda x:len(x)==1,items_list)) # 只有过一次交互的用户数\n",
    "    f[34] = len(filter(lambda x:len(x)==2,items_list)) # 有过两次交互的用户数\n",
    "    f[35] = len(filter(lambda x:len(x)==3,items_list)) # 有过三次交互的用户数\n",
    "    items = sorted(items, key=lambda x:x[0], reverse=True)\n",
    "    f[0] = len(filter(lambda x:x[0]<=1 and x[1]==1, items)) # 最后1天点击次数\n",
    "    f[1] = len(filter(lambda x:x[0]<=1 and x[1]==2, items)) # 最后1天加收次数\n",
    "    f[2] = len(filter(lambda x:x[0]<=1 and x[1]==3, items)) # 最后1天加购次数\n",
    "    f[3] = len(filter(lambda x:x[0]<=1 and x[1]==4, items)) # 最后1天购买次数\n",
    "    f[4] = len(filter(lambda x:x[0]==2 and x[1]==1, items)) # 倒数第2天点击次数\n",
    "    f[5] = len(filter(lambda x:x[0]==2 and x[1]==2, items)) # 倒数第2天加收次数\n",
    "    f[6] = len(filter(lambda x:x[0]==2 and x[1]==3, items)) # 倒数第2天加购次数\n",
    "    f[7] = len(filter(lambda x:x[0]==2 and x[1]==4, items)) # 倒数第2天购买次数\n",
    "    f[8] = len(filter(lambda x:x[0]==3 and x[1]==1, items)) # 倒数第3天点击次数\n",
    "    f[9] = len(filter(lambda x:x[0]==3 and x[1]==2, items)) # 倒数第3天加收次数\n",
    "    f[10] = len(filter(lambda x:x[0]==3 and x[1]==3, items)) # 倒数第3天加购次数\n",
    "    f[11] = len(filter(lambda x:x[0]==3 and x[1]==4, items)) # 倒数第3天购买次数\n",
    "    f[12] = len(filter(lambda x:x[0]<=7 and x[1]==1, items)) # 最后1周点击次数\n",
    "    f[13] = len(filter(lambda x:x[0]<=7 and x[1]==2, items)) # 最后1周加收次数\n",
    "    f[14] = len(filter(lambda x:x[0]<=7 and x[1]==3, items)) # 最后1周加购次数\n",
    "    f[15] = len(filter(lambda x:x[0]<=7 and x[1]==4, items)) # 最后1周购买次数\n",
    "    f[16] = len(filter(lambda x:x[0]<=14 and x[1]==1, items)) # 最后2周点击次数\n",
    "    f[17] = len(filter(lambda x:x[0]<=14 and x[1]==2, items)) # 最后2周加收次数\n",
    "    f[18] = len(filter(lambda x:x[0]<=14 and x[1]==3, items)) # 最后2周加购次数\n",
    "    f[19] = len(filter(lambda x:x[0]<=14 and x[1]==4, items)) # 最后2周购买次数\n",
    "    f[20] = min(1.0,round(1.0*(f[3]+f[7]+f[11])/(f[0]+f[4]+f[8]),4)) if (f[0]+f[4]+f[8]) else 0.0 # 最后3天点击转化率\n",
    "    f[21] = min(1.0,round(1.0*(f[3]+f[7]+f[11])/(f[1]+f[5]+f[9]),4)) if (f[1]+f[5]+f[9])!=0 else 0.0 # 最后3天加收转化率\n",
    "    f[22] = min(1.0,round(1.0*(f[3]+f[7]+f[11])/(f[2]+f[6]+f[10]),4)) if f[2]!=0 else 0.0 # 最后3天加购转化率\n",
    "    f[23] = min(1.0,round(1.0*f[7]/f[4],4)) if f[4]!=0 else 0.0 # 最后2周点击转化率\n",
    "    f[24] = min(1.0,round(1.0*f[7]/f[5],4)) if f[5]!=0 else 0.0 # 最后2周加收转化率\n",
    "    f[25] = min(1.0,round(1.0*f[7]/f[6],4)) if f[6]!=0 else 0.0 # 最后2周加购转化率\n",
    "    buy = filter(lambda x:x[1]==4, items)\n",
    "    last = buy[-1][0] if len(buy)!=0 else inf\n",
    "    f[26] = len(buy) # 购买总次数 \n",
    "    f[27] = len(filter(lambda x:x[0]==last and x[1]==1, items)) # 最后一次发生购买的当天发生的点击次数\n",
    "    f[28] = len(filter(lambda x:x[0]==last and x[1]==2, items)) # 最后一次发生购买的当天发生的加收次数\n",
    "    f[29] = len(filter(lambda x:x[0]==last and x[1]==3, items)) # 最后一次发生购买的当天发生的加购次数\n",
    "    f[36] = round(1.0*len(items)/f[30],4) if f[30]!=0 else 0.0 # 人均交互次数\n",
    "    return \"\\t\".join([str(i) for i in f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "global etime\n",
    "global subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = sc.textFile(uid_iid_path, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "############################           用户特征           ###########################\n",
    "####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract1_user(line):\n",
    "    import time\n",
    "    (uid, iid, ict) = line.strip().split(\"\\t\")[0].split(\" \")\n",
    "    items = filter(lambda x:x[0]>0, [(int(time.mktime(time.strptime('2014-'+etime,'%Y-%m-%d-%H'))-time.mktime(time.strptime('2014-'+i.split(\",\")[0],'%Y-%m-%d-%H')))/(24*3600)+1, int(i.split(\",\")[1])) for i in line.strip().split(\"\\t\")[1].split(\" \")])\n",
    "    return (uid,items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract2_user(items_list):\n",
    "    import itertools\n",
    "    items, items_buy, items_buy_3, f, inf = [], [], [], [0]*39, 100\n",
    "    f[32] = len(items_list) # 交互商品数\n",
    "    for i in items_list:\n",
    "        if len(filter(lambda x:x[1]==4,i))>0:\n",
    "            items_buy.append(i)\n",
    "        if len(filter(lambda x:x[1]==4 and x[0]<=3,i))>0:\n",
    "            items_buy_3.append(i)\t\n",
    "        items.extend(i)\n",
    "    f[33] = len(items_buy) # 购买商品数\n",
    "    f[34] = len(items_buy_3) # 三天内购买商品数\n",
    "    f[35] = len(filter(lambda x:len(x)==1,items_list)) # 只有过一次交互的商品数\n",
    "    f[36] = len(filter(lambda x:len(x)==2,items_list)) # 有过两次交互的商品数\n",
    "    f[37] = len(filter(lambda x:len(x)==3,items_list)) # 有过三次交互的商品数\n",
    "    items = sorted(items, key=lambda x:x[0], reverse=True)\n",
    "    buy = filter(lambda x:x[1]==4, items)\n",
    "    last = buy[-1][0] if len(buy)!=0 else inf\n",
    "    f[24] = len(filter(lambda x:x[0]<=1 and x[1]==1, items)) # 最后1天点击次数\n",
    "    f[25] = len(filter(lambda x:x[0]<=1 and x[1]==2, items)) # 最后1天加收次数\n",
    "    f[26] = len(filter(lambda x:x[0]<=1 and x[1]==3, items)) # 最后1天加购次数\n",
    "    f[27] = len(filter(lambda x:x[0]<=1 and x[1]==4, items)) # 最后1天购买次数\n",
    "    f[28] = len(filter(lambda x:x[0]<=3 and x[1]==1, items)) # 最后3天点击次数\n",
    "    f[29] = len(filter(lambda x:x[0]<=3 and x[1]==2, items)) # 最后3天加收次数\n",
    "    f[30] = len(filter(lambda x:x[0]<=3 and x[1]==3, items)) # 最后3天加购次数\n",
    "    f[31] = len(filter(lambda x:x[0]<=3 and x[1]==4, items)) # 最后3天购买次数\n",
    "    f[0] = len(filter(lambda x:x[0]<=7 and x[1]==1, items)) # 最后1周点击次数\n",
    "    f[1] = len(filter(lambda x:x[0]<=7 and x[1]==2, items)) # 最后1周加收次数\n",
    "    f[2] = len(filter(lambda x:x[0]<=7 and x[1]==3, items)) # 最后1周加购次数\n",
    "    f[3] = len(filter(lambda x:x[0]<=7 and x[1]==4, items)) # 最后1周购买次数\n",
    "    f[4] = len(filter(lambda x:x[0]<=21 and x[1]==1, items)) # 最后3周点击次数\n",
    "    f[5] = len(filter(lambda x:x[0]<=21 and x[1]==2, items)) # 最后3周加收次数\n",
    "    f[6] = len(filter(lambda x:x[0]<=21 and x[1]==3, items)) # 最后3周加购次数\n",
    "    f[7] = len(filter(lambda x:x[0]<=21 and x[1]==4, items)) # 最后3周购买次数\n",
    "    f[8] = min(1.0,round(1.0*f[3]/f[0],4)) if f[0]!=0 else 0.0 # 最后1周点击转化率\n",
    "    f[9] = min(1.0,round(1.0*f[3]/f[1],4)) if f[1]!=0 else 0.0 # 最后1周加收转化率\n",
    "    f[10] = min(1.0,round(1.0*f[3]/f[2],4)) if f[2]!=0 else 0.0 # 最后1周加购转化率\n",
    "    f[11] = min(1.0,round(1.0*f[7]/f[4],4)) if f[4]!=0 else 0.0 # 最后3周点击转化率\n",
    "    f[12] = min(1.0,round(1.0*f[7]/f[5],4)) if f[5]!=0 else 0.0 # 最后3周加收转化率\n",
    "    f[13] = min(1.0,round(1.0*f[7]/f[6],4)) if f[6]!=0 else 0.0 # 最后3周加购转化率\n",
    "    f[14] = last # 最后一次购买距离天数\n",
    "    f[15] = len(set([item[0] for item in items if item[0]<=3])) # 最后3天内交互天数\n",
    "    f[16] = len(set([item[0] for item in items if item[0]<=7])) # 最后1周内交互天数\n",
    "    f[17] = len(set([item[0] for item in items if item[0]<=21])) # 最后3周内交互天数\n",
    "    f[18] = items[-1][0] if len(items)!=0 else inf # 最后1次交互距离天数\n",
    "    inter = [len(list(i)) for _,i in itertools.groupby(items, lambda x: x[0])]\n",
    "    f[19] = len(inter) #交互天数\n",
    "    f[20] = max(inter) if len(inter)!=0 else 0 #交互最多的一天交互次数\n",
    "    f[21] = len(filter(lambda x:x[0]<=1 and x[1]==4, items)) # 最后1天购买次数\n",
    "    f[22] = len(filter(lambda x:x[0]<=3 and x[1]==4, items)) # 最后3天购买次数\n",
    "    f[23] = len(filter(lambda x:x[0]<=7 and x[1]==4, items)) # 最后7天购买次数\n",
    "    f[38] = round(1.0*len(items)/f[32],4) if f[32]!=0 else 0.0 # 用户对每件商品的平均交互次数\n",
    "    return \"\\t\".join([str(i) for i in f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines = sc.textFile(uid_iid_path, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "############################       用户-品牌特征          ###########################\n",
    "####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract1_user_brand(line):\n",
    "    import time\n",
    "    (uid, iid, ict) = line.strip().split(\"\\t\")[0].split(\" \")\n",
    "    if subset.has_key(ict):\n",
    "        items = filter(lambda x:x[0]>0, [(int(time.mktime(time.strptime('2014-'+etime,'%Y-%m-%d-%H'))-time.mktime(time.strptime('2014-'+i.split(\",\")[0],'%Y-%m-%d-%H')))/(24*3600)+1, int(i.split(\",\")[1])) for i in line.strip().split(\"\\t\")[1].split(\" \")])\n",
    "        return (uid+\"\\t\"+ict,items)\n",
    "    else:\n",
    "        return (\"\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract2_user_brand(items_list):\n",
    "    import itertools\n",
    "    items = []\n",
    "    for i in items_list:\n",
    "        items.extend(i)\n",
    "    items = sorted(items, key=lambda x:x[0], reverse=True) if len(items)!=0 else []\n",
    "    f, inf = [0]*26, 100\n",
    "    buy = filter(lambda x:x[1]==4, items)\n",
    "    last = buy[-1][0] if len(buy)!=0 else inf\n",
    "    a1 = filter(lambda x:x[0]<last and x[1]==1, items)\n",
    "    a2 = filter(lambda x:x[0]<last and x[1]==2, items)\n",
    "    a3 = filter(lambda x:x[0]<last and x[1]==3, items)\n",
    "    # 基本统计特征\n",
    "    f[0] = a2[-1][0] if len(a2)!=0 else inf # 购买后最后一次加入收藏夹距离天数\n",
    "    f[1] = a3[-1][0] if len(a3)!=0 else inf # 购买后最后一次加入购物车距离天数\n",
    "    f[2] = len(a1) # 购买后点击次数\n",
    "    f[3] = len(a2) # 购买后加收次数\n",
    "    f[4] = len(a3) # 购买后加购次数\n",
    "    f[5] = len(filter(lambda x:x[0]<=1, items)) # 最后1天交互次数\n",
    "    f[6] = len(filter(lambda x:x[0]==2, items)) # 倒数第2天交互次数\n",
    "    f[7] = len(filter(lambda x:x[0]==3, items)) # 倒数第3天交互次数\n",
    "    f[8] = len(filter(lambda x:x[0]==4, items)) # 倒数第4天交互次数\n",
    "    f[9] = len(filter(lambda x:x[0]<=7, items)) # 最后7天交互次数\n",
    "    f[10] = len(buy) # 历史购买次数\n",
    "    f[11] = last # 最后一次购买距离天数\n",
    "    f[12] = len(set([item[0] for item in items if item[0]<=3])) # 最后3天内交互天数\n",
    "    f[13] = len(set([item[0] for item in items if item[0]<=7])) # 最后1周内交互天数\n",
    "    f[14] = len(set([item[0] for item in items if item[0]<=21])) # 最后3周内交互天数\n",
    "    f[15] = items[-1][0] if len(items)!=0 else inf # 最后1次交互距离天数\n",
    "    inter = [len(list(i)) for _,i in itertools.groupby(items, lambda x: x[0])]\n",
    "    f[16] = len(inter) #交互天数\n",
    "    f[17] = max(inter) if len(inter)!=0 else 0 #交互最多的一天交互次数\n",
    "    f[18] = len(filter(lambda x:x[0]<=1 and x[1]==4, items)) # 最后1天购买次数\n",
    "    f[19] = len(filter(lambda x:x[0]<=2 and x[1]==4, items)) # 最后2天购买次数\n",
    "    f[20] = len(filter(lambda x:x[0]<=3 and x[1]==4, items)) # 最后3天购买次数\n",
    "    f[21] = len(filter(lambda x:x[0]<=7 and x[1]==4, items)) # 最后7天购买次数\n",
    "    f[22] = len(filter(lambda x:x[1]==1, items)) # 总点击次数\n",
    "    f[23] = len(filter(lambda x:x[1]==2, items)) # 总添加收藏夹次数\n",
    "    f[24] = len(filter(lambda x:x[1]==3, items)) # 总加购次数\n",
    "    f[25] = items[0][0]-items[-1][0]+1 if len(items)!=0 else 0 # 第一次交互到最后一次交互的持续时间\n",
    "    return \"\\t\".join([str(i) for i in f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines = sc.textFile(uid_iid_path, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "############################       用户-商品特征          ###########################\n",
    "####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_user_prod(line):\n",
    "    import time\n",
    "    import itertools\n",
    "    (uid, iid, ict) = line.strip().split(\"\\t\")[0].split(\" \")\n",
    "    if subset.has_key(iid):\n",
    "        items = filter(lambda x:x[0]>0, [(int(time.mktime(time.strptime('2014-'+etime,'%Y-%m-%d-%H'))-time.mktime(time.strptime('2014-'+i.split(\",\")[0],'%Y-%m-%d-%H')))/(24*3600)+1, int(i.split(\",\")[1])) for i in line.strip().split(\"\\t\")[1].split(\" \")])\n",
    "        f, inf = [0]*22, 100\n",
    "        buy = filter(lambda x:x[1]==4, items)\n",
    "        last = buy[-1][0] if len(buy)!=0 else inf\n",
    "        a1 = filter(lambda x:x[0]<last and x[1]==1, items) \n",
    "        a2 = filter(lambda x:x[0]<last and x[1]==2, items) \n",
    "        a3 = filter(lambda x:x[0]<last and x[1]==3, items)\n",
    "        # 基本统计特征\n",
    "        f[0] = a2[-1][0] if len(a2)!=0 else inf # 购买后最后一次加入收藏夹距离天数\n",
    "        f[1] = a3[-1][0] if len(a3)!=0 else inf # 购买后最后一次加入购物车距离天数\n",
    "        f[2] = len(a1) # 购买后点击次数\n",
    "        f[3] = len(a2) # 购买后加收次数\n",
    "        f[4] = len(a3) # 购买后加购次数\n",
    "        f[5] = len(filter(lambda x:x[0]<=1, items)) # 最后1天交互次数\n",
    "        f[6] = len(filter(lambda x:x[0]==2, items)) # 倒数第2天交互次数\n",
    "        f[7] = len(filter(lambda x:x[0]==3, items)) # 倒数第3天交互次数\n",
    "        f[8] = len(filter(lambda x:x[0]==4, items)) # 倒数第4天交互次数\n",
    "        f[9] = len(filter(lambda x:x[0]<=7, items)) # 最后7天交互次数\n",
    "        f[10] = len(buy) # 历史购买次数\n",
    "        f[11] = last # 最后一次购买距离天数\n",
    "        f[12] = len(set([item[0] for item in items if item[0]<=3])) # 最后3天内交互天数\n",
    "        f[13] = len(set([item[0] for item in items if item[0]<=7])) # 最后1周内交互天数\n",
    "        f[14] = len(set([item[0] for item in items if item[0]<=21])) # 最后3周内交互天数\n",
    "        f[15] = items[-1][0] if len(items)!=0 else inf # 最后1次交互距离天数\n",
    "        inter = [len(list(i)) for _,i in itertools.groupby(items, lambda x: x[0])]\n",
    "        f[16] = len(inter) #交互天数\n",
    "        f[17] = max(inter) if len(inter)!=0 else 0 # 交互最多的一天交互次数\n",
    "        f[18] = len(filter(lambda x:x[1]==1, items)) # 总点击次数\n",
    "        f[19] = len(filter(lambda x:x[1]==2, items)) # 总添加收藏夹次数\n",
    "        f[20] = len(filter(lambda x:x[1]==3, items)) # 总加购次数\n",
    "        f[21] = items[0][0]-items[-1][0]+1 if len(items)!=0 else 0 # 第一次交互到最后一次交互的持续时间\n",
    "        return (uid+\"\\t\"+iid+\"\\t\"+ict+\"\\t\"+\"\\t\".join([str(i) for i in f]))\n",
    "    else:\n",
    "        return (\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "############################          验证集提取          ############################\n",
    "####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract1_valid(line):\n",
    "    import time\n",
    "    (uid, iid, ict), items = line.strip().split(\"\\t\")[0].split(\" \"), filter(lambda x:x[1]==4, [(i.split(\",\")[0], int(i.split(\",\")[1])) for i in line.strip().split(\"\\t\")[1].split(\" \")])\n",
    "    return (uid+\"\\t\"+iid, [\"-\".join(item[0].split(\"-\")[:2])+\"-0\" for item in items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = {}\n",
    "for line in fileinput.input(train_set_path):\n",
    "    subset[line.strip().split(\",\")[0]] = True\n",
    "def f(x): return x\n",
    "counts = lines.filter(lambda x : subset.has_key(x.strip().split(\"\\t\")[0].split(\" \")[1]))\\\n",
    "              .map(lambda x : extract1_valid(x))\\\n",
    "              .flatMapValues(f)\\\n",
    "              .map(lambda x : x[1]+\"\\t\"+x[0])\n",
    "output = counts.saveAsTextFile(\"./data/buy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "# LOOP WORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target, etime, subset = \"12-19-0\", \"12-18-23\", {}\n",
    "target, etime, subset = \"12-18-0\", \"12-17-23\", {}\n",
    "# target, etime, subset = \"12-17-0\", \"12-16-23\", {}\n",
    "# target, etime, subset = \"12-16-0\", \"12-15-23\", {}\n",
    "# target, etime, subset = \"12-15-0\", \"12-14-23\", {}\n",
    "# target, etime, subset = \"12-14-0\", \"12-13-23\", {}\n",
    "# target, etime, subset = \"12-13-0\", \"12-12-23\", {}\n",
    "# target, etime, subset = \"12-12-0\", \"12-11-23\", {}\n",
    "# target, etime, subset = \"12-11-0\", \"12-10-23\", {}\n",
    "# target, etime, subset = \"12-10-0\", \"12-09-23\", {}\n",
    "# target, etime, subset = \"12-09-0\", \"12-08-23\", {}\n",
    "# target, etime, subset = \"12-08-0\", \"12-07-23\", {}\n",
    "# target, etime, subset = \"12-07-0\", \"12-06-23\", {}\n",
    "# target, etime, subset = \"12-06-0\", \"12-05-23\", {}\n",
    "# target, etime, subset = \"12-05-0\", \"12-04-23\", {}\n",
    "# target, etime, subset = \"12-04-0\", \"12-03-23\", {}\n",
    "# target, etime, subset = \"12-03-0\", \"12-04-23\", {}\n",
    "# target, etime, subset = \"12-02-0\", \"12-01-23\", {}\n",
    "# target, etime, subset = \"12-01-0\", \"11-30-23\", {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in fileinput.input(train_set_path):\n",
    "    subset[line.split(\",\")[0]] = True\n",
    "counts = lines.map(lambda x : extract1_item(x))\\\n",
    "              .filter(lambda x : x[0]!=\"\")\\\n",
    "              .groupByKey()\\\n",
    "              .map(lambda x : x[0]+\"\\t\"+extract2_item(x[1]))\n",
    "output = counts.saveAsTextFile(feature_path+target+\"/prod/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in fileinput.input(train_set_path):\n",
    "        subset[line.split(\",\")[0]] = True\n",
    "counts = lines.map(lambda x : extract1_user(x))\\\n",
    "              .groupByKey()\\\n",
    "              .map(lambda x : x[0]+\"\\t\"+extract2_user(x[1]))\n",
    "output = counts.saveAsTextFile(feature_path+target+\"/user/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in fileinput.input(train_set_path):\n",
    "    subset[line.strip().split(\",\")[2]] = True\n",
    "counts = lines.map(lambda x : extract1_user_brand(x))\\\n",
    "              .filter(lambda x : x[0]!=\"\")\\\n",
    "              .groupByKey()\\\n",
    "              .map(lambda x : x[0]+\"\\t\"+extract2_user_brand(x[1]))\n",
    "output = counts.saveAsTextFile(feature_path+target+\"/user_ict/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in fileinput.input(train_set_path):\n",
    "        subset[line.strip().split(\",\")[0]] = True\n",
    "counts = lines.map(lambda x : extract_user_prod(x))\\\n",
    "              .filter(lambda x : x!=\"\")\n",
    "output = counts.saveAsTextFile(feature_path+target+\"/user_prod/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "############################           特征合并           ###########################\n",
    "####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in fileinput.input(train_set_path):\n",
    "    subset[line.strip().split(\",\")[0]] = True\n",
    "feature_user_prod = sc.textFile(feature_path+target+'/user_prod', 1).map(lambda x : (x.strip().split(\"\\t\")[0]+\"\\t\"+x.strip().split(\"\\t\")[2],x.strip()))\n",
    "feature_user_ict = sc.textFile(feature_path+target+'/user_ict', 1).map(lambda x : (x.strip().split(\"\\t\")[0]+\"\\t\"+x.strip().split(\"\\t\")[1],\"\\t\".join(x.strip().split(\"\\t\")[2:])))\n",
    "feature_prod = sc.textFile(feature_path+target+'/prod', 1).map(lambda x : (x.strip().split(\"\\t\")[0],\"\\t\".join(x.strip().split(\"\\t\")[1:])))\n",
    "feature_user = sc.textFile(feature_path+target+'/user', 1).map(lambda x : (x.strip().split(\"\\t\")[0],\"\\t\".join(x.strip().split(\"\\t\")[1:])))\n",
    "counts = feature_user_prod.join(feature_user_ict).map(lambda x:(x[1][0].split(\"\\t\")[1],x[1][0]+\"\\t\"+x[1][1]))\n",
    "counts = counts.join(feature_prod).map(lambda x:(x[1][0].split(\"\\t\")[0],x[1][0]+\"\\t\"+x[1][1]))\n",
    "counts = counts.join(feature_user).map(lambda x:x[1][0]+\"\\t\"+x[1][1])\n",
    "counts = counts.filter(lambda x : int(x.strip().split(\"\\t\")[3:][9])>0 and int(x.strip().split(\"\\t\")[3:][17])>=2)\n",
    "output = counts.saveAsTextFile(\"./data/prediction/\"+target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "#############################             预测            ###########################\n",
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prediction(line):\n",
    "#     feature = [float(line.strip().split(\"\\t\")[3:][i]) for i in xrange(len(line.strip().split(\"\\t\")[3:])) if i in [1,2,4,5,9,12,15,17,18,20,23,27,48,50,62,66]]\n",
    "#     return (sum([clfs[i].predict_proba(feature)[0][0] for i in xrange(N)]), \"\\t\".join(line.strip().split(\"\\t\")[:2]))\n",
    "\n",
    "# global N\n",
    "# global clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 3\n",
    "# import time\n",
    "# import random\n",
    "# import pickle\n",
    "# import fileinput\n",
    "# time_start = time.time()\n",
    "# featureset = [line.strip() for line in fileinput.input(\"./data/feature_list.txt\")]\n",
    "# buyset = {}\n",
    "# for line in sc.textFile('./data/buy', 1).collect():\n",
    "#     buyset[line.strip()] = True\n",
    "# X_train_0, Y_train_0, X_train_1, Y_train_1 = [], [], [], []\n",
    "# dates = [\"12-15-0\",\"12-16-0\"]\n",
    "# for date in dates:\n",
    "#     for line in sc.textFile('./data/prediction/'+date, 1).collect():\n",
    "#     # for line in fileinput.input(\"prediction/\"+date+\".txt\"):\n",
    "#         if buyset.has_key(date+\"\\t\"+\"\\t\".join(line.strip().split(\"\\t\")[:2])):\n",
    "#             # X_train_1.append([float(i) for i in line.strip().split(\"\\t\")[3:]])\n",
    "#             X_train_1.append([float(line.strip().split(\"\\t\")[3:][i]) for i in xrange(len(line.strip().split(\"\\t\")[3:])) if i in [1,2,4,5,9,12,15,17,18,20,23,27,48,50,62,66]])\n",
    "#             Y_train_1.append(1)\n",
    "#         else:\n",
    "#             # X_train_0.append([float(i) for i in line.strip().split(\"\\t\")[3:]])\n",
    "#             X_train_0.append([float(line.strip().split(\"\\t\")[3:][i]) for i in xrange(len(line.strip().split(\"\\t\")[3:])) if i in [1,2,4,5,9,12,15,17,18,20,23,27,48,50,62,66]])\n",
    "#             Y_train_0.append(0)\t\n",
    "# X_train, Y_train = [[] for i in xrange(N)], [[] for i in xrange(N)]\n",
    "# for i in xrange(N):\n",
    "#     for j in random.sample([j for j in xrange(len(X_train_0))], 10*len(X_train_1)):\n",
    "#         X_train[i].append(X_train_0[j])\n",
    "#         Y_train[i].append(Y_train_0[j])\n",
    "#     X_train[i].extend(X_train_1)\n",
    "#     Y_train[i].extend(Y_train_1)\n",
    "# print X_train[0][0]\n",
    "# print Y_train[0][0]\n",
    "# print len(Y_train[0])\n",
    "# # clfs = [RandomForestClassifier(n_estimators=20,max_features=10,max_depth=3,random_state=1,class_weight={0:1,1:1}) for i in xrange(N)]\n",
    "# clfs = [GradientBoostingClassifier(n_estimators=50, max_depth=3, learning_rate=0.1) for i in xrange(N)]\n",
    "# # criterion = \"gini\"|\"entropy\"\n",
    "# # clf = Pipeline([\n",
    "# #   ('feature_selection', LinearSVC(penalty=\"l1\", dual=False)),\n",
    "# #   # ('classification', RandomForestClassifier(n_estimators=20,max_features=30,max_depth=3,random_state=1,class_weight={1:2}))\n",
    "# #    ('classification', RandomForestClassifier(n_estimators=100,max_features=30,max_depth=3,random_state=1,class_weight={0:5}))\n",
    "# #   # ('classification', GradientBoostingClassifier(n_estimators=50, max_depth=3, learning_rate=0.1))\n",
    "# #   # ('classification', SVC(kernel='rbf', probability=True, class_weight={1:10}))\n",
    "# # ])\n",
    "# for i in xrange(N):\n",
    "#     clfs[i].fit(X_train[i],Y_train[i])\n",
    "# # for i in xrange(len(clf.feature_importances_)):\n",
    "# #   if clf.feature_importances_[i] >= 0.01:\n",
    "# #     print i, clf.feature_importances_[i], featureset[i]\n",
    "# ############################ 备份模型 ############################ \n",
    "# # pickle.dump(clf,open('clf.p', 'wb'))\n",
    "# # clf = pickle.load(open(\"clf.p\",\"rb\"))\n",
    "# ############################ 备份模型 ############################ \n",
    "# print \"training finished!~\"\n",
    "# pred = \"12-17-0\"\n",
    "# lines = sc.textFile('./data/prediction/'+pred, 1)\n",
    "# counts = lines.map(lambda x : prediction(x)).sortByKey().collect()\n",
    "# recall, precision, correct = len([1 for key in buyset.keys() if key.strip().split(\"\\t\")[0] == pred]), 400, len([1 for item in counts[:400] if buyset.has_key(pred+\"\\t\"+item[1])])\n",
    "# print \"prediction finished!~\"\n",
    "# print recall, precision, correct, 1.0*correct/recall, 1.0*correct/precision, 2*1.0*correct/recall*1.0*correct/precision/(1.0*correct/recall+1.0*correct/precision)\n",
    "# with open(\"tianchi_mobile_recommendation_predict.csv\",\"w\") as f:\n",
    "#     f.write(\"user_id,item_id\\n\")\n",
    "#     for item in counts[:400]:\n",
    "#         f.write(\",\".join(item[1].split(\"\\t\"))+\"\\n\")\n",
    "# time_end = time.time()\n",
    "# print time_end-time_start"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
