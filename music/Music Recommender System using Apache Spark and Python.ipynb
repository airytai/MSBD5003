{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Recommender System using Apache Spark and Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import *\n",
    "import random\n",
    "from operator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1059637, 1000010, 238),\n",
       " (1059637, 1000049, 1),\n",
       " (1059637, 1000056, 1),\n",
       " (1059637, 1000062, 11),\n",
       " (1059637, 1000094, 1),\n",
       " (1059637, 1000112, 423),\n",
       " (1059637, 1000113, 5),\n",
       " (1059637, 1000114, 2),\n",
       " (1059637, 1000123, 2),\n",
       " (1059637, 1000130, 19129)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parser1(s):\n",
    "    temp = s.split(\" \")\n",
    "    return (int(temp[0]),int(temp[1]),int(temp[2]))\n",
    "def parser2(s):\n",
    "    temp = s.split(\"\\t\")\n",
    "    return (int(temp[0]),int(temp[1]))\n",
    "    return list\n",
    "def parser3(s):\n",
    "    temp = s.split(\"\\t\")\n",
    "    return (int(temp[0]),temp[1])\n",
    "temp = sc.textFile(\"D:/HKUST/Big Data Computing/Project/Reference/MusicRecommendation-Spark--master/user_artist_data_small.txt\").map(parser1)\n",
    "artistAlias = sc.textFile(\"D:/HKUST/Big Data Computing/Project/Reference/MusicRecommendation-Spark--master/artist_alias_small.txt\").map(parser2)\n",
    "aliasDic = artistAlias.collectAsMap()\n",
    "userArtistData = temp.map(lambda x: (x[0], aliasDic.get(x[1], x[1]), x[2]))\n",
    "artistData = sc.textFile(\"D:/HKUST/Big Data Computing/Project/Reference/MusicRecommendation-Spark--master/artist_data_small.txt\").map(parser3)\n",
    "#print aliasDic\n",
    "userArtistData.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1027859, 1252408),\n",
       " (1017615, 668),\n",
       " (6745885, 1268522),\n",
       " (1018110, 1018110),\n",
       " (1014609, 1014609),\n",
       " (6713071, 2976),\n",
       " (1014175, 1014175),\n",
       " (1008798, 1008798),\n",
       " (1013851, 1013851),\n",
       " (6696814, 1030672)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artistAlias.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1240105, 'André Visior'),\n",
       " (1240113, 'riow arai'),\n",
       " (1240132, 'Outkast & Rage Against the Machine'),\n",
       " (6776115, '小松正夫'),\n",
       " (1030848, \"Raver's Nature\"),\n",
       " (6671601, 'Erguner, Kudsi'),\n",
       " (1106617, 'Bloque'),\n",
       " (1240185, 'Lexy & K. Paul'),\n",
       " (6671631, 'Rev. W.M. Mosley'),\n",
       " (6671632, 'Labelle, Patti')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artistData.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 1059637 has a total play count of 674412 and a mean play count of 1878.5849582172702.\n",
      "User 2064012 has a total play count of 548427 and a mean play count of 9455.637931034482.\n",
      "User 2069337 has a total play count of 393515 and a mean play count of 1519.3629343629343.\n"
     ]
    }
   ],
   "source": [
    "def transform(x):\n",
    "    l = list(x[1])\n",
    "    counts = []\n",
    "    for i in range(0,len(l)):\n",
    "        play = l[i][2]\n",
    "        counts.append(play)\n",
    "    total = sum(counts)\n",
    "    avg = total/len(l)\n",
    "    return (x[0],total,avg)  \n",
    "temp = userArtistData.groupBy(lambda x: x[0]).map(lambda x: (x[0],list(x[1]))).map(transform)\n",
    "#print temp.collect()\n",
    "top = temp.takeOrdered(3, key=lambda x: -x[1])\n",
    "for i in range(0,len(top)):\n",
    "    print(\"User \" + str(top[i][0]) +\" has a total play count of \"+ str(top[i][1]) +\" and a mean play count of \"+ str(top[i][2]) +\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1059637, 1000049, 1), (1059637, 1000056, 1), (1059637, 1000114, 2)]\n",
      "[(1059637, 1000010, 238), (1059637, 1000062, 11), (1059637, 1000123, 2)]\n",
      "[(1059637, 1000094, 1), (1059637, 1000112, 423), (1059637, 1000113, 5)]\n",
      "29552\n",
      "9907\n",
      "10022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PythonRDD[58] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData,validationData,testData = userArtistData.randomSplit([6,2,2], 13)\n",
    "print(trainData.take(3))\n",
    "print(validationData.take(3))\n",
    "print(testData.take(3))\n",
    "print(trainData.count())\n",
    "print(validationData.count())\n",
    "print(testData.count())\n",
    "trainData.cache()\n",
    "validationData.cache()\n",
    "testData.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelEval(model,validation):\n",
    "    import operator\n",
    "    userIds = validation.map(lambda x: x[0]).distinct().collect()\n",
    "    #print len(userIds)\n",
    "    artistIds = list(artistData.collectAsMap().keys())\n",
    "    temp = trainData.map(lambda x: (x[0], x[1])).filter(lambda x: x[0] in userIds).groupByKey().map(lambda x: (x[0], list(x[1])))\n",
    "    valiSet = temp.flatMap(lambda x: [(x[0],a) for a in artistIds if a not in x[1]])\n",
    "    # .groupBy(lambda x:x[0]).map(lambda x:(x[0],len(list(elmt[1] for elmt in x[1])))).collect()\n",
    "    # temp = artistData.flatMap(lambda x: [(y, x[0]) for y in userIds])\n",
    "    # valiSet = temp.filter(lambda x: x not in trainSet)\n",
    "    # print valiSet.groupBy(lambda x:x[0]).map(lambda x:(x[0],len(list(elmt[1] for elmt in x[1])))).collect()\n",
    "    # print 'here'\n",
    "    predictions = bestModel.predictAll(valiSet).map(lambda x: (x[0], x[1], x[2])).groupBy(lambda x:x[0]).map(lambda x:(x[0],sorted(list(x[1]),key=operator.itemgetter(2),reverse=True)))\n",
    "    predictions = predictions.map(lambda x:(x[0],list(elmt[1] for elmt in x[1])))\n",
    "    cmprSet = validation.groupBy(lambda x:x[0]).map(lambda x:(x[0],list(x[1]))).map(lambda x:(x[0],list(elmt[1] for elmt in x[1])))\n",
    "    p = predictions.collect()\n",
    "    cdic =  cmprSet.collectAsMap()  \n",
    "    scores = []\n",
    "    for i in range(0,len(p)):\n",
    "        user = p[i][0]\n",
    "        plist = p[i][1]\n",
    "        clist = cdic[user]\n",
    "        plen = len(plist)\n",
    "        clen = len(clist)\n",
    "        #print 'ppppppppp'\n",
    "        #print plen\n",
    "        #print 'cccccccccc'\n",
    "        #print clen\n",
    "        count = 0\n",
    "        score = 0\n",
    "        if plen >= clen:\n",
    "            for j in range(0,clen):\n",
    "                if plist[j] in clist:\n",
    "                    count +=1\n",
    "        score = float(float(count)/clen)\n",
    "        scores.append(score)\n",
    "    return sum(scores)/len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model score for rank 2 is 0.06086241846519619\n",
      "The model score for rank 4 is 0.07256298165544033\n",
      "The model score for rank 6 is 0.07832541606495551\n",
      "The model score for rank 8 is 0.07270293840529879\n",
      "The model score for rank 10 is 0.07766516111812562\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
    "for elmt in range(2,11,2):\n",
    "    bestModel = ALS.trainImplicit(trainData, rank=elmt)\n",
    "    print('The model score for rank ' + str(elmt) + ' is '+ str(modelEval(bestModel,validationData)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07896140645360168\n"
     ]
    }
   ],
   "source": [
    "bestModel = ALS.trainImplicit(trainData, rank=6)\n",
    "print(modelEval(bestModel, testData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist 0: Something Corporate\n",
      "Artist 1: My Chemical Romance\n",
      "Artist 2: The Used\n",
      "Artist 3: Green Day\n",
      "Artist 4: U2\n"
     ]
    }
   ],
   "source": [
    "temp = bestModel.recommendProducts(1059637, 5)\n",
    "lists = []\n",
    "for i in range(0,len(temp)):\n",
    "    lists.append(temp[i][1])\n",
    "    print(\"Artist \"+str(i)+\": \"+str(artistData.lookup(temp[i][1])[0],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
