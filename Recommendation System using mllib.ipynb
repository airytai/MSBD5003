{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import *\n",
    "import random\n",
    "from operator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "userItemFile = sc.textFile(\"tianchi_fresh_comp_train_user.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser1(s):\n",
    "    temp = s.split(\"\\t\")\n",
    "    return (int(temp[0]),int(temp[1]),int(temp[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "userItem = userItemFile.map(parser1).map(lambda x: ((x[0],x[1]),x[2])).reduceByKey(lambda x,y: x+y).map(lambda x: (x[0][0],x[0][1],x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238376\n",
      "79463\n",
      "79437\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PythonRDD[11] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData,validationData,testData = userItem.randomSplit([6,2,2], 13)\n",
    "# print(trainData.take(3))\n",
    "# print(validationData.take(3))\n",
    "# print(testData.take(3))\n",
    "print(trainData.count())\n",
    "print(validationData.count())\n",
    "print(testData.count())\n",
    "trainData.cache()\n",
    "validationData.cache()\n",
    "testData.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ALS(train_data, validation_data, num_iters, reg_param, ranks):\n",
    "    \"\"\"\n",
    "    Grid Search Function to select the best model based on RMSE of hold-out data\n",
    "    \"\"\"\n",
    "    # initial\n",
    "    min_error = float('inf')\n",
    "    best_rank = -1\n",
    "    best_regularization = 0\n",
    "    best_model = None\n",
    "    for rank in ranks:\n",
    "        for reg in reg_param:\n",
    "            # train ALS model\n",
    "            model = ALS.train(\n",
    "                ratings=train_data,    # (userID, productID, rating) tuple\n",
    "                iterations=num_iters,\n",
    "                rank=rank,\n",
    "                lambda_=reg,           # regularization param\n",
    "                seed=99)\n",
    "            # make prediction\n",
    "            valid_data = validation_data.map(lambda p: (p[0], p[1]))\n",
    "            predictions = model.predictAll(valid_data).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "            # get the rating result\n",
    "            ratesAndPreds = validation_data.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n",
    "            # get the RMSE\n",
    "            MSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n",
    "            error = math.sqrt(MSE)\n",
    "            print('{} latent factors: validation RMSE is {}'.format(rank, error))\n",
    "            if error < min_error:\n",
    "                min_error = error\n",
    "                best_rank = rank\n",
    "                best_regularization = reg\n",
    "                best_model = model\n",
    "    print('\\nThe best model has {} latent factors'.format(best_rank))\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-param config\n",
    "num_iterations = 5\n",
    "ranks = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "reg_params = [0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 latent factors: validation RMSE is 6.80573981701\n",
      "4 latent factors: validation RMSE is 6.00615239206\n",
      "6 latent factors: validation RMSE is 5.64247588863\n",
      "8 latent factors: validation RMSE is 5.38437091669\n",
      "10 latent factors: validation RMSE is 5.27461613662\n",
      "12 latent factors: validation RMSE is 5.20068317767\n",
      "14 latent factors: validation RMSE is 5.1696832275\n",
      "16 latent factors: validation RMSE is 5.08510276692\n",
      "18 latent factors: validation RMSE is 5.06791137454\n",
      "20 latent factors: validation RMSE is 5.06389790431\n",
      "\n",
      "The best model has 20 latent factors\n"
     ]
    }
   ],
   "source": [
    "final_model = train_ALS(trainData, validationData, num_iterations, reg_params, ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item 1: 299050468\n",
      "Item 2: 287845290\n",
      "Item 3: 258745390\n",
      "Item 4: 148597624\n",
      "Item 5: 94776053\n"
     ]
    }
   ],
   "source": [
    "temp = final_model.recommendProducts(104448961, 5)\n",
    "lists = []\n",
    "for i in range(0,len(temp)):\n",
    "    lists.append(temp[i][1])\n",
    "    print(\"Item \"+str(i+1)+\": \"+str(temp[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The out-of-sample RMSE of rating predictions is', 5.2407)\n"
     ]
    }
   ],
   "source": [
    "# make prediction using test data\n",
    "test_data = testData.map(lambda p: (p[0], p[1]))\n",
    "predictions = final_model.predictAll(test_data).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "# get the rating result\n",
    "ratesAndPreds = testData.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n",
    "# get the RMSE\n",
    "MSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n",
    "error = math.sqrt(MSE)\n",
    "print('The out-of-sample RMSE of rating predictions is', round(error, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - PySpark",
   "language": "python",
   "name": "apache_toree_pyspark"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "pygments_lexer": "python",
   "version": "2.7.12\n"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
