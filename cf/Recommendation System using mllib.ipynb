{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import *\n",
    "import random\n",
    "from operator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "userItemFile = sc.textFile(\"D:/HKUST/Big Data Computing/Project/data/fresh_comp_offline/tianchi_fresh_comp_train_user.txt\")\n",
    "itemFile = sc.textFile(\"D:/HKUST/Big Data Computing/Project/data/fresh_comp_offline/tianchi_fresh_comp_train_item.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10001082\\t285259775\\t1',\n",
       " '10001082\\t4368907\\t1',\n",
       " '10001082\\t4368907\\t1',\n",
       " '10001082\\t53616768\\t1',\n",
       " '10001082\\t151466952\\t1']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userItemFile.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['100002303\\t3368',\n",
       " '100003592\\t7995',\n",
       " '100006838\\t12630',\n",
       " '100008089\\t7791',\n",
       " '100012750\\t9614']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemFile.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser1(s):\n",
    "    temp = s.split(\"\\t\")\n",
    "    return (int(temp[0]),int(temp[1]),int(temp[2]))\n",
    "\n",
    "def parser2(s):\n",
    "    temp = s.split(\"\\t\")\n",
    "    return (int(temp[0]),int(temp[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "userItem = userItemFile.map(parser1).map(lambda x: ((x[0],x[1]),x[2])).reduceByKey(lambda x,y: x+y).map(lambda x: (x[0][0],x[0][1],x[1]))\n",
    "item = itemFile.map(parser2).map(lambda x: (x[0],x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10001082, 53616768, 9),\n",
       " (10001082, 151466952, 3),\n",
       " (10001082, 298397524, 3),\n",
       " (10001082, 32104252, 3),\n",
       " (10001082, 396795886, 3)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userItem.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "397276"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userItem.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(100002303, 3368),\n",
       " (100003592, 7995),\n",
       " (100006838, 12630),\n",
       " (100008089, 7791),\n",
       " (100012750, 9614)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "620918"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(10001082, 151466952, 3), (10001082, 298397524, 3), (10001082, 22667958, 3)]\n",
      "[(10001082, 53616768, 9), (10001082, 32104252, 3), (10001082, 125083630, 1)]\n",
      "[(10001082, 396795886, 3), (10001082, 275221686, 34), (10001082, 97441652, 1)]\n",
      "237839\n",
      "79807\n",
      "79630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PythonRDD[28] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData,validationData,testData = userItem.randomSplit([6,2,2], 13)\n",
    "print(trainData.take(3))\n",
    "print(validationData.take(3))\n",
    "print(testData.take(3))\n",
    "print(trainData.count())\n",
    "print(validationData.count())\n",
    "print(testData.count())\n",
    "trainData.cache()\n",
    "validationData.cache()\n",
    "testData.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelEval(model,validation):\n",
    "    import operator\n",
    "    userIds = validation.map(lambda x: x[0]).distinct().collect()\n",
    "    itemIds = list(item.collectAsMap().keys())\n",
    "    temp = trainData.map(lambda x: (x[0], x[1])).filter(lambda x: x[0] in userIds).groupByKey().map(lambda x: (x[0], list(x[1])))\n",
    "    valiSet = temp.flatMap(lambda x: [(x[0],a) for a in itemIds if a not in x[1]])\n",
    "    predictions = bestModel.predictAll(valiSet).map(lambda x: (x[0], x[1], x[2])).groupBy(lambda x:x[0]).map(lambda x:(x[0],sorted(list(x[1]),key=operator.itemgetter(2),reverse=True)))\n",
    "    predictions = predictions.map(lambda x:(x[0],list(elmt[1] for elmt in x[1])))\n",
    "    cmprSet = validation.groupBy(lambda x:x[0]).map(lambda x:(x[0],list(x[1]))).map(lambda x:(x[0],list(elmt[1] for elmt in x[1])))\n",
    "    p = predictions.collect()\n",
    "    cdic =  cmprSet.collectAsMap()  \n",
    "    scores = []\n",
    "    for i in range(0,len(p)):\n",
    "        user = p[i][0]\n",
    "        plist = p[i][1]\n",
    "        clist = cdic[user]\n",
    "        plen = len(plist)\n",
    "        clen = len(clist)\n",
    "        count = 0\n",
    "        score = 0\n",
    "        if plen >= clen:\n",
    "            for j in range(0,clen):\n",
    "                if plist[j] in clist:\n",
    "                    count += 1\n",
    "        score = float(float(count)/clen)\n",
    "        scores.append(score)\n",
    "    return sum(scores)/len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
    "score = 0\n",
    "best_rank = 2\n",
    "for elmt in range(2,11,2):\n",
    "    bestModel = ALS.trainImplicit(trainData, rank=elmt)\n",
    "    best_model_score = modelEval(bestModel,validationData)\n",
    "    if model_score > score:\n",
    "        score = best_model_score\n",
    "        best_rank = elmt\n",
    "\n",
    "print('The best model score for rank ' + str(best_rank) + ' is '+ str(best_model_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
